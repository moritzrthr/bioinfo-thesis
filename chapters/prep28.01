

unten 2 teile von vorher und anchher deine aufgabe ist es nun anhand der skizze und dieser infos den mittleren teil zu schreiben auf englisch


puh kerine ahnung wie struktur sein soll

erst erkalerung auf independent real world dataset anwenden kurz sagen es is unpublished von clinspect m 300 glioma samples

dann sagen welche daten: 6,5mio spektren  siehe “Data Acquisition and Preprocessing”

dann sagen welche settings um die peptides zu bekommen und warum MQ: als baseline damit man vgl klann und validieren kann unsere ergebnisse und sehen kann ob wir beyond gehen koennen


>>>>>HIER DIE ALTEN OUTLINES



\section{Biological Application}

To evaluate the practical utility of the model, it was applied to an independent Glioma cancer dataset.



\subsection{Data Acquisition and Preprocessing}

The primary data source consisted of Orbitrap-based mass spectrometry raw files (.raw) from cancer proteomic studies. To ensure compatibility with the deep learning framework, raw files were converted into .mgf format using the \texttt{ThermoRawFileParser} (v2.0.0), which facilitates the extraction of metadata and spectral information \cite{Hulstaert2020}.

All MS1 (precursor scans) and MS3  scans were removed for the analysis.









\subsection{Getting peptide sequences}



\paragraph{De Novo Sequencing Configuration}

The sequencing of the TMT-labeled spectra was performed using the adapted Modanovo framework. To ensure high-quality sequence predictions and to accommodate the systematic shifts introduced by TMT, the following parameters were applied:

\begin{itemize}

   \item \textbf{Mass Tolerances:} The precursor mass tolerance was set to 50 ppm to account for potential drift in large-scale datasets. The isotope error range was restricted to $[0, 3]$.

   \item \textbf{Spectrum Processing:} To reduce noise, only the 150 most intense peaks per spectrum (\texttt{n\_peaks}) within an $m/z$ range of 50.0 to 2500.0 were retained. Peaks within a 2.0 Da window of the precursor $m/z$ were removed to prevent interference.

   \item \textbf{Sequence Constraints:} A minimum peptide length of 6 amino acids and a maximum of 100 were enforced. For the decoding process, a beam search with a width of $n\_beams = 1$ was utilized, focusing on the top-ranked match.

   \item \textbf{Quality Control:} Only spectra with a precursor charge of $\leq 10$ and a relative intensity threshold of 0.01 were processed.

\end{itemize}



\paragraph{Database Search Configuration (MaxQuant)}

To provide a complementary ground-truth baseline, all Glioma datasets were processed using MaxQuant (version 2.1.3.0) \cite{Tyanova2016}. The search was conducted against the human reference proteome (UniProt UP000005640).



The search parameters were harmonized with the experimental design:

\begin{itemize}

   \item \textbf{Protease:} Trypsin/P was specified, allowing for cleavage C-terminal to Lysine and Arginine, even when followed by Proline.

   \item \textbf{Fixed Modifications:} Carbamidomethylation of cysteine (+57.021 Da) was set as a static modification.

   \item \textbf{Variable Modifications:} To capture the regulatory landscape of the cancer samples, oxidation (M) and phosphorylation (S/T/Y) were included in the search space.

\end{itemize}




>>>>>HIER DER DARAUFFOLGENDE TEIL


\subsection{Peptide Alignment and Sequence Validation}
To validate the biological origin of the predicted \textit{de novo} sequences and to distinguish between known peptides and potential novel discoveries, a sequence alignment against the reference proteome was performed. This step is crucial because \textit{de novo} models predict sequences solely based on spectral features, which may include errors or biologically plausible variations not present in the reference database.

\paragraph{Mass-Spectrometric Ambiguities and Encoding Strategy}
A fundamental challenge in de novo peptide sequencing is the existence of isobaric or near-isobaric amino acid residues. Since the models primarily operates on mass-to-charge ratios ($m/z$), it identifies mass shifts rather than chemical identities. While transformer-based architectures can theoretically also learn to consider aminoacid context when mass shifts overlap, this still remains unevaluated and therefore we resolve the ambiguities. 

We identified several critical ambiguities:
\begin{itemize}
    \item \textbf{I/L Equivalence:} Leucine (L) and Isoleucine (I) are structural isomers with an identical monoisotopic mass of $113.08406$ Da, making them indistinguishable in HCD spectra.
    \item \textbf{Deamidation-induced Ambiguities:} The deamidation of Glutamine (Q) and Asparagine (N) results in a mass increase of $+0.984016$ Da. This shift leads to these pairs:
    \begin{itemize}
        \item Glutamic acid (E, $129.042593$ Da) and deamidated Glutamine (Q[+0.98], $129.042594$ Da).
        \item Aspartic acid (D, $115.026943$ Da) and deamidated Asparagine (N[+0.98], $115.026943$ Da).
    \end{itemize}
    \item \textbf{Pyro-glutamate Formations:} Ambiguities also occur between Pyro-glu E and Pyro-glu Q. However, as these appeared in less than 1\% of the detected spectra in our dataset, they were not explicitly encoded to avoid over-complicating the search space.
\end{itemize}

\paragraph{BLASTp Configuration and Ambiguity Handling}
Alignment was executed using \texttt{Protein-Protein BLAST} (version 2.17.0+) against the human reference proteome (UniProt UP000005640). Because the reference proteome consists of unmodified sequences, a direct match of a deamidated peptide (predicted as D or E by the model) against a genomic N or Q would fail under standard parameters.

To resolve this, we implemented a specialized encoding strategy using IUPAC ambiguity codes:
\begin{itemize}
    \item All predicted \textbf{D} residues (which could be $N[+0.98]$) were replaced with \textbf{B} (asparagine or aspartic acid).
    \item All predicted \textbf{E} residues (which could be $Q[+0.98]$) were replaced with \textbf{Z} (glutamine or glutamic acid).
\end{itemize}

An alternative approach would have been the implementation of a custom substitution matrix. However, the BLASTp  does not support user-defined matrices for short peptide searches without extensive modification of the source code. Therefore, we utilized the \texttt{PAM30} matrix, which is optimized for short sequences and natively supports the \texttt{B} and \texttt{Z} codes.

% --- Visual Example for Thesis ---
\vspace{1em}
\noindent \textbf{Example of IUPAC Encoding for Deamidation Alignment:}
\begin{center}
\small
\begin{tabular}{rll}
    \textbf{Reference Proteome:} & \texttt{A V G \textbf{D} L T S \textbf{Q} R} & \\
    \textbf{De-novo Prediction:} & \texttt{A V G \color{red}{N} L T S \color{red}{E} R} & \textit{\footnotesize (Potential Mismatches)} \\
    \noalign{\smallskip}
    \cline{1-2}
    \noalign{\smallskip}
    \textbf{Standard BLASTp:}   & \texttt{A V G \color{red}{-} L T S \color{red}{-} R} & \textbf{\color{red}{Mismatch}} \\
    \textbf{Our Strategy (PAM30):} & \texttt{A V G \color{blue}{B} L T S \color{blue}{Z} R} & \textbf{\color{blue}{Perfect Match*}} \\
\end{tabular}
\end{center}
\textit{\footnotesize *Note: Both sequences are converted to IUPAC codes B (N/D) and Z (Q/E) prior to alignment, allowing the PAM30 matrix to score them as identical residues.}
\vspace{1em}

\paragraph{Alignment Parameters}
The alignment parameters were adjusted to account for the short nature of tryptic peptides. We set an E-value threshold of $2000$, as the small search space of a single peptide often results in high E-values despite perfect sequence identity. Furthermore, we used a \texttt{qcov\_hsp\_perc} of $80$ and disabled composition-based statistics (\texttt{comp\_based\_stats}) to prevent score inflation and ensure that short matches were not statistically penalized \cite{Altschul1997, Kersey2004}.


\paragraph{Post-Alignment Filtering and SNP Analysis}
The resulting alignments were further enriched to identify Single Nucleotide Polymorphisms (SNPs) and truncation events. To account for sequences extending beyond protein termini or alignment gaps, the full query and target sequences were retrieved. 
The number of mismatches was calculated by considering the \texttt{B} and \texttt{Z} equivalences. For each remaining mismatch, an automated codon-lookup was performed. A mismatch was classified as "SNP-explainable" if the transition between the predicted amino acid and the reference residue could be achieved by a single nucleotide substitution in the underlying codon. 

Cases involving gaps or truncations where the query extended beyond the reference boundaries were excluded from the SNP analysis to maintain high confidence in the mutation mapping.






>>>>HIER DER VORHERIGE TEIL



\section{Finetuning Datasets}



\subsection{Data Selection and Composition}

For the training and evaluation of the adapted model, a robust dataset was curated to ensure high-quality spectral representations. The fundamental requirement for supervised learning in this context is the availability of ground truth sequences associated with high-resolution fragment spectra. Data were integrated from various sources, initially stored in CSV and mzML formats, and subsequently compiled into a unified Mascot Generic Format (MGF) file. This format allows for a streamlined input pipeline where the peptide sequence is explicitly linked to its corresponding spectrum \cite{Deutsch2012}.





The fine-tuning process utilizes two distinct datasets to adapt the model to TMT-labeled spectra while maintaining performance on unlabeled data (see Figure \ref{fig:datasplits}).





\begin{figure}[H][htbp]

    \centering

    \includegraphics{plots/methods/datasplits.png}

    \caption{Composition of the fine-tuning dataset showing the distribution of Peptide-Spectrum Matches (PSMs). The majority (82\%) consists of TMT-labeled MultiPTM data, complemented by a 18\% Replay-Set to maintain performance on unlabeled spectra.}

    \label{fig:datasplits}

\end{figure}



\subsection{TMT-labeled Data}

The primary dataset for adapting the model to isobaric labeling is derived from the PROSPECT-MultiPTM collection \cite{Zeng2024}. These data are based on the ProteomeTools project, a large-scale synthetic peptide library effort \cite{Zolg2017}.



\paragraph{Instrumentation and Fragmentation}

All spectra were acquired using Thermo Scientific Orbitrap instruments (Q Exactive and Orbitrap Fusion series). Fragmentation was performed exclusively using Higher-energy Collisional Dissociation (HCD), resulting in high-resolution MS2 spectra.



\paragraph{Labeling and Modifications}

The peptides in this dataset are labeled with Tandem Mass Tags (TMT). The chemical modification manifests as a specific mass shift at the peptide N-terminus and on the $\epsilon$-amino group of all Lysine (K) residues. The exact mass shifts follow the Unimod definitions and are encoded using the ProForma standard \cite{Leis2022}.



\paragraph{Dataset Statistics}

The TMT-labeled dataset is partitioned as follows:

\begin{itemize}

    \item \textbf{Training Set:} 3,683,888 PSMs covering 75,268 unique peptides.

    \item \textbf{Validation Set:} 363,612 PSMs covering 7,751 unique peptides.

    \item \textbf{Test Set:} 364,867 PSMs covering 9,415 unique peptides.

\end{itemize}



\subsection{Non-TMT Data (Replay Set)}

To prevent catastrophic forgetting during the fine-tuning process, a diverse reference dataset of unlabeled (non-TMT) spectra is included. This "Replay Set" consists of a mixture of 80\% MultiPTM data and 20\% data from the MassIVE Knowledge Base (MassIVE-KB) \cite{Wang2018}.



\paragraph{Dataset Statistics}

The non-TMT reference data is partitioned as follows:

\begin{itemize}

    \item \textbf{Training Set:} 784,128 PSMs covering 289,568 unique peptides.

    \item \textbf{Validation Set:} 98,396 PSMs covering 23,004 unique peptides.

    \item \textbf{Test Set:} 93,453 PSMs covering 19,141 unique peptides.

\end{itemize}



\subsection{Modification Distribution and Heatmap Analysis}

To evaluate the coverage of the training data, we visualized the modification density across different residues. This approach was closely oriented towards the \textit{Modanovo} framework to ensure comparability and systematic evaluation of PTM-residue pairs \cite{KlaprothAndrade2025}.



\begin{figure}[H][htbp]

    \centering

    \begin{subfigure}{\textwidth}

        \centering

        \includegraphics{plots/methods/heatmap_TMT_fixed.png}

        \caption{Modification distribution for the TMT-labeled dataset.}

        \label{fig:heatmap_tmt}

    \end{subfigure}

    \hfill

    \begin{subfigure}{\textwidth}

        \centering

        \includegraphics{plots/methods/heatmap_NonTMT_fixed.png}

        \caption{Modification distribution for the non-TMT Replay Set.}

        \label{fig:heatmap_nontmt}

    \end{subfigure}

    \caption{Heatmaps showing the log-scaled spectral counts for various PTMs across amino acid residues. While the TMT dataset (a) shows high density for N-terminal and Lysine labeling, the Replay Set (b) provides a broader PTM diversity including Phosphorylation and Glycosylation.}

    \label{fig:heatmaps_combined}

\end{figure}



As shown in Figure \ref{fig:heatmaps_combined}, the current data selection strategy provides high coverage for common PTMs such as Oxidation (M) and Phosphorylation (S, T, Y). However, there remains significant optimization potential. Specifically, certain rare PTM-residue combinations or complex multiplexed modifications (e.g., Ubiquitinylation + TMT) exhibit lower spectral counts, which might limit the model's ability to generalize on extremely sparse clinical samples.



\subsection{Quality Filtering and Pre-processing}

To minimize noise and prevent the model from learning experimental artifacts, several quality filtering steps were applied:

\begin{itemize}

    \item \textbf{Peak Cleaning:} Spectra containing no intensity information or empty peaks were removed.

    \item \textbf{Bias Mitigation:} To prevent overfitting to hyper-abundant peptides, a threshold of 229 PSMs per unique peptide sequence was enforced.

    \item \textbf{Data Leakage Prevention:} Following the \textit{Modanovo} protocol, a strict data split was implemented. Peptides with specific modifications (e.g., $PEP[ph]$) were assigned to the same split as their unmodified counterparts ($PEP$) to ensure the model learns chemical principles rather than memorizing sequences \cite{KlaprothAndrade2025}.

\end{itemize}







The final dataset was structured into an 80/10/10 split (training, validation, and testing). To specifically address the TMT expansion, an 80/20 balance between TMT-labeled and unlabeled spectra was maintained, and all non-TMT spectra originating from TMT-specific experiments were removed to ensure label consistency. Furthermore, Unimod syntax was translated into mass-shift syntax (e.g., [+229.163]) to align with the model's vocabulary.





\section{Training Protocol}



Model fine-tuning was initialized from the publicly available Modanovo checkpoint, allowing the model to build upon previously learned representations of peptide fragmentation and spectral structure \cite{KlaprothAndrade2025}. In contrast to partial adaptation strategies, all model parameters were updated during fine-tuning, i.e.\ no layers were frozen, enabling global adaptation to TMT-specific fragmentation effects and modification patterns.



The underlying transformer architecture was kept identical to the base Modanovo configuration, comprising a model dimension of $d_{\text{model}} = 512$, 8 self-attention heads, a feed-forward dimension of 1024, and 9 layers each in the encoder and decoder stacks. This architectural consistency ensures that any observed performance differences can be attributed to the fine-tuning procedure rather than structural changes.



Optimization hyperparameters were deliberately chosen to favor stable adaptation of the pre-trained weights. A low learning rate of $1 \times 10^{-6}$ was used to prevent catastrophic forgetting while still permitting gradual adjustment to TMT-induced shifts in fragmentation behavior. To further stabilize early training dynamics, a warm-up phase of two epochs was applied. Regularization was introduced via a weight decay of $1 \times 10^{-5}$ and label smoothing with a factor of 0.01, improving generalization in the presence of heterogeneous modification patterns.



Training was performed using mixed-precision arithmetic with \textit{bf16} precision, reducing memory consumption and improving computational efficiency on modern GPU architectures without compromising numerical stability \cite{Micikevicius2017}. Model selection was based on validation loss, and the checkpoint with the lowest validation loss was retained for all downstream analyses.





\section{Evaluation Strategy and Performance Metrics}





To rigorously assess the performance of the TMT-adapted de novo sequencing model, a multi-faceted evaluation framework was established. The primary objective is to determine how well the model generalizes to TMT-labeled spectra and various post-translational modifications (PTMs) compared to traditional database-driven assignments.



\subsection{Confidence Scoring and Peptide Ranking}

Each peptide-spectrum match (PSM) generated by the model is assigned a confidence score to facilitate ranking and quality control. Following the architecture of Transformer-based models like Casanovo and Modanovo, we derive a peptide-level score by calculating the arithmetic mean of the individual amino acid confidence scores, which are obtained from the softmax output at each decoding step \cite{Yilmaz2022}.



To ensure the physical plausibility of the predictions, a mass-matching constraint is applied. If the calculated mass of the predicted sequence (including PTMs and TMT labels) deviates from the observed precursor mass beyond a defined tolerance (e.g., 10 ppm), the peptide score is penalized. This integration of spectral evidence and thermodynamic constraints is crucial for distinguishing between high-confidence sequences and plausible but incorrect mass-shift combinations.



\subsection{Precision-Coverage Analysis and Stratification}

The core metric for evaluating the model's predictive power is the precision-coverage curve. This allows for a threshold-independent assessment of how many peptides can be identified at a given reliability level. For this study, we specifically focus on the Area Under the Precision-Coverage Curve (AUPCC), calculated using the trapezoidal rule \cite{Pedregosa2011}.



A critical aspect of our evaluation is the **stratified analysis**. To understand the specific impact of the TMT expansion, we evaluate the performance separately for:

\begin{itemize}

    \item \textbf{TMT-labeled spectra:} To measure the success of the model adaptation to systematic mass shifts.

    \item \textbf{Unlabeled (non-TMT) spectra:} To ensure that the model retains its general sequencing capabilities without losing performance on standard data (preventing "catastrophic forgetting").

\end{itemize}



Precision ($P$) and Coverage ($C$) at a score threshold $t$ are defined as:

\begin{equation}

    P(t) = \frac{|\text{Correct PSMs with score} \geq t|}{|\text{Total predictions with score} \geq t|}

\end{equation}

\begin{equation}

    C(t) = \frac{|\text{Predictions with score} \geq t|}{|\text{Total ground truth identifications}|}

\end{equation}



A PSM is considered correct if the sequence exactly matches the ground truth identified by a database search (e.g., MaxQuant or MSFragger), treating isobaric amino acids such as Leucine and Isoleucine as equivalent \cite{KlaprothAndrade2025}.



To uncover biological insights beyond standard searches, we evaluate the precision for specific PTM-amino acid combinations. For a given modification (e.g., Phosphorylation at T), we subset the ground truth data to include all peptides containing this specific shift. This granular view ensures that the model's ability to handle complex, multiplexed PTM patterns is validated across both TMT and non-TMT backgrounds.










